# 8 layers
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,4x64,2x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,4x64,2x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,4x64,2x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,4x64,2x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,4x64,2x128 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_8x128 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_8x128 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_8x128 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_8x128 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_8x128 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_8x128 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_8x128 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_8x128 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_8x128 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_8x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,4x64,2x128 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_16 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_16 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_16 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_16 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_16 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_2x12x2 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_2x12x2 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_2x12x2 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_2x12x2 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_2x12x2 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_4x8x4 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_4x8x4 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_4x8x4 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_4x8x4 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_mamba_4x8x4 training.optimizer.lr=0.002

# 6 layers
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_1x128,4x64,1x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_1x128,4x64,1x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_1x128,4x64,1x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_1x128,4x64,1x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_1x128,4x64,1x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,2x64,2x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,2x64,2x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,2x64,2x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,2x64,2x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_2x128,2x64,2x128 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_6x128 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_6x128 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_6x128 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_6x128 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_cosformer_6x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_1x128,4x64,1x128 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_2x128,2x64,2x128 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=selective_copying_vanilla_6x128 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

