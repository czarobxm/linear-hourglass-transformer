# # 8 layers
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,4x2048,2x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,4x2048,2x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,4x2048,2x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,4x2048,2x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,4x2048,2x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_8x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_8x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_8x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_8x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_8x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_8x4096 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,4x2048,2x4096 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# # 6 layers
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,2x2048,2x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,2x2048,2x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,2x2048,2x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,2x2048,2x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_2x4096,2x2048,2x4096 training.optimizer.lr=0.002

sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_1x4096,4x2048,1x4096 training.optimizer.lr=0.0001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_1x4096,4x2048,1x4096 training.optimizer.lr=0.0002
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_1x4096,4x2048,1x4096 training.optimizer.lr=0.0005
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_1x4096,4x2048,1x4096 training.optimizer.lr=0.001
sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_1x4096,4x2048,1x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_6x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_6x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_6x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_6x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_cosformer_6x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0002
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0005
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.001
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.002

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_2x4096,2x2048,2x4096 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_1x4096,4x2048,1x4096 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true

# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.0005 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.001 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true
# sbatch --gres=gpu:1 --cpus-per-task=1 --ntasks=1 --mem=120G --time=2-0 --partition=plgrid-gpu-a100 --account=plgllmparamgr-gpu-a100 poetry run python3 train_single_gpu.py --config-name=enwik9_vanilla_6x4096 training.optimizer.lr=0.002 model.hourglass.attention_downsampling=true model.hourglass.attention_upsampling=true